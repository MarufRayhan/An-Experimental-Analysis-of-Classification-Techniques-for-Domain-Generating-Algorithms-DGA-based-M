{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bjit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "nltk.download('punkt')\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from datetime import datetime\n",
    "import pickle as pickle\n",
    "from sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_chk(labels_train,features_train,labels_test,predictions,fitted_model,model_name,n1,n2):\n",
    "    with open(\"test.txt\",'a',encoding = 'utf-8') as f:\n",
    "        evaluation = {\n",
    "            'Model name': model_name,\n",
    "            'N_Gram Range' : [n1,n2],\n",
    "            'Training Set Accuracy': accuracy_score(labels_train, fitted_model.predict(features_train)),\n",
    "            'Test Set Accuracy': accuracy_score(labels_test, predictions),\n",
    "            'Precision score: ': precision_score(labels_test, predictions),\n",
    "            'Recall score: ': recall_score(labels_test, predictions),\n",
    "            'f1 score: ':  f1_score(labels_test, predictions),\n",
    "            'log loss': log_loss(labels_test, predictions,eps=1e-15)\n",
    "\n",
    "        }\n",
    "        cls_report = classification_report(labels_test, predictions)\n",
    "        crosstab = pd.crosstab(labels_test , predictions)\n",
    "        f.write(str(evaluation))\n",
    "        f.write('\\n')\n",
    "        f.write(str(cls_report))\n",
    "        f.write('\\n')\n",
    "        f.write(str(crosstab))\n",
    "        f.write('\\n')\n",
    "    return evaluation, cls_report, crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_result(predictions_test, y_test):\n",
    "    print('Accuracy: ',accuracy_score(labels_test, predictions))\n",
    "    print('Precision score: ', precision_score(y_valid, predictions))\n",
    "    print('Recall score: ', recall_score(y_valid, predictions))\n",
    "    print('f1 score: ',  f1_score(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(labels_test,predictions):\n",
    "    cm = confusion_matrix(labels_test, predictions)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                     index=['Safe', 'Malware'],\n",
    "                     columns=['Safe', 'Malware'])\n",
    "\n",
    "    plt.figure(figsize=(4.5, 3))\n",
    "    sns.heatmap(cm_df, annot=True,fmt = 'd')\n",
    "    plt.title(accuracy_score(labels_test, predictions))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
